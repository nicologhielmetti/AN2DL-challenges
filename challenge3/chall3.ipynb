{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chall3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "lRO-dwZJuRKA"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicologhielmetti/AN2DL-challenges/blob/master/challenge3/chall3.ipynb\" target=\"_parent\">\n",
        "    <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZpmn88cRoE8"
      },
      "source": [
        "import json, os\n",
        "from functools import partial\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import keras.layers as layers\n",
        "import keras.models as models\n",
        "from keras.initializers import orthogonal\n",
        "from keras.optimizers import Adam\n",
        "import shutil\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from datetime import datetime"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxKfWGwf5FII",
        "outputId": "ab7e3e1f-ed08-4035-9755-3924b302176c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlhygyiVnN7-"
      },
      "source": [
        "#!pip install gdown\n",
        "#!gdown https://drive.google.com/uc?id=1tglwr5cbQbzrSLmJlHmz33htFUw0yzc4\n",
        "!unzip -qq /content/drive/MyDrive/anndl-2020-vqa.zip -d \"/content/drive/MyDrive/\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "0JQ6LsaZuRKH"
      },
      "source": [
        "#!unzip -qq VQA_Dataset.zip -d VQA_Dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xK7JXN60ien"
      },
      "source": [
        "random.seed(96)\n",
        "\n",
        "cwd = os.getcwd()\n",
        "\n",
        "datasetName = os.path.join(cwd,'drive/MyDrive/VQA_Dataset')\n",
        "trainJsonName = 'train.json'\n",
        "validJsonName = 'valid.json'\n",
        "testJsonName  = 'test_questions.json'\n",
        "testJsonNameCorrect = 'test.json'\n",
        "imagesPath = os.path.join(datasetName, 'Images')\n",
        "trainJsonPath = os.path.join(datasetName, trainJsonName)\n",
        "validJsonPath = os.path.join(datasetName, validJsonName)\n",
        "testJsonPath  = os.path.join(datasetName, testJsonName)\n",
        "testJsonPathCorrect  = os.path.join(datasetName, testJsonNameCorrect)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siaKwgfhgtOk"
      },
      "source": [
        "def create_split_files(file_path, train_val_split):\n",
        "    with open(file_path,'r') as json_dataset:\n",
        "        data = json.load(json_dataset)\n",
        "\n",
        "    tot_list = list()\n",
        "    for k,v in data.items():\n",
        "        tot_list.append(v)\n",
        "\n",
        "    train_list = random.sample(tot_list, int(len(tot_list) * (1 - train_val_split)))\n",
        "    validation_list = [i for i in tot_list if i not in train_list]\n",
        "\n",
        "    with open(\"drive/MyDrive/VQA_Dataset/train.json\", \"w\") as train:\n",
        "        json.dump(train_list, train)\n",
        "        train.close()\n",
        "    with open(\"drive/MyDrive/VQA_Dataset/valid.json\", \"w\") as validation:\n",
        "        json.dump(validation_list, validation)\n",
        "        validation.close()\n",
        "    \n",
        "    #assert len([x for x in tot_list if x in train_list and x in validation_list]) == 0\n",
        "\n",
        "def generate_correct_test_file(testJsonPath):\n",
        "    with open(testJsonPath,'r') as json_dataset:\n",
        "        data = json.load(json_dataset)\n",
        "\n",
        "    test_list = list()\n",
        "    for k,v in data.items():\n",
        "        test_list.append(v)\n",
        "\n",
        "    with open(\"drive/MyDrive/VQA_Dataset/test.json\", \"w\") as test:\n",
        "        json.dump(test_list, test)\n",
        "        test.close()\n",
        "\n",
        "def create_train_test_dirs(json_definition, dataset_path, split_name):\n",
        "    dest_dir = os.path.join(dataset_path, split_name)\n",
        "    if not os.path.isdir(dest_dir):\n",
        "      os.mkdir(dest_dir)\n",
        "      os.mkdir(os.path.join(dest_dir, split_name))\n",
        "    for k,v in json_definition.items():\n",
        "        try:\n",
        "            shutil.copy(\n",
        "                os.path.join(dataset_path, \"Images\", k +'.png'),\n",
        "                os.path.join(dest_dir, split_name, k +'.png')\n",
        "            )\n",
        "        except FileNotFoundError as e:\n",
        "            print(\"Split name: \" + split_name + \". File not found: \" + str(e))\n",
        "            continue\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MRoHGbaRwCD"
      },
      "source": [
        "\n",
        "create_split_files(os.path.join(datasetName, 'train_questions_annotations.json'), 0.3)\n",
        "generate_correct_test_file(testJsonPath)\n",
        "\n",
        "with open(trainJsonPath,'r') as json_file_train, open(validJsonPath, 'r') as json_file_valid, open(testJsonPathCorrect, 'r') as json_file_test:\n",
        "    data_train = json.load(json_file_train)\n",
        "    data_valid = json.load(json_file_valid)\n",
        "    data_test = json.load(json_file_test)\n",
        "\n",
        "    json_file_train.close()\n",
        "    json_file_valid.close()\n",
        "    json_file_test.close()\n",
        "\n",
        "\n",
        "os.chdir(cwd)\n",
        "#create_train_test_dirs(data_train, datasetName, 'train')\n",
        "#create_train_test_dirs(data_valid, datasetName, 'validation')\n",
        "#create_train_test_dirs(data_test, datasetName, 'test')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "F2sbKp0cuRKI"
      },
      "source": [
        "# RUN only for train the autoenc\n",
        "dest_dir = os.path.join(datasetName, \"ImagesExt\")\n",
        "if not os.path.isdir(dest_dir):\n",
        "  os.mkdir(dest_dir)\n",
        "shutil.move(imagesPath, dest_dir)\n",
        "imagesPath = os.path.join(dest_dir, \"Images\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "GPOeAGuUuRKJ",
        "outputId": "4e7bf419-6325-49d9-c8f6-f1012582833c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# RUN only for train the autoenc\n",
        "img_size = (256, 256)\n",
        "preproc_fun_fixed = partial(tf.keras.preprocessing.image.smart_resize, size=img_size)\n",
        "batch_size = 32\n",
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,\n",
        "                                                          data_format='channels_last',\n",
        "                                                          preprocessing_function=preproc_fun_fixed,\n",
        "                                                          validation_split=0.3)\n",
        "train_data = datagen.flow_from_directory(datasetName+'/ImagesExt', img_size, class_mode='input',\n",
        "                                         batch_size=batch_size, subset=\"training\")\n",
        "valid_data = datagen.flow_from_directory(datasetName+'/ImagesExt', img_size, class_mode='input',\n",
        "                                         batch_size=batch_size, subset=\"validation\")\n",
        "\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 20534 images belonging to 1 classes.\n",
            "Found 8799 images belonging to 1 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUWJZpBuSYBJ"
      },
      "source": [
        "# RUN only for train the autoenc\n",
        "def Conv2DLayer(x, filters, kernel, strides, padding, block_id, kernel_init=orthogonal()):\n",
        "    prefix = f'block_{block_id}_'\n",
        "    x = layers.Conv2D(filters, kernel_size=kernel, strides=strides, padding=padding,\n",
        "                      kernel_initializer=kernel_init, name=prefix+'conv')(x)\n",
        "    x = layers.LeakyReLU(name=prefix+'lrelu')(x)\n",
        "    x = layers.Dropout(0.2, name=prefix+'drop')((x))\n",
        "    x = layers.BatchNormalization(name=prefix+'conv_bn')(x)\n",
        "    return x\n",
        "\n",
        "def Transpose_Conv2D(x, filters, kernel, strides, padding, block_id, kernel_init=orthogonal()):\n",
        "    prefix = f'block_{block_id}_'\n",
        "    x = layers.Conv2DTranspose(filters, kernel_size=kernel, strides=strides, padding=padding,\n",
        "                               kernel_initializer=kernel_init, name=prefix+'de-conv')(x)\n",
        "    x = layers.LeakyReLU(name=prefix+'lrelu')(x)\n",
        "    x = layers.Dropout(0.2, name=prefix+'drop')((x))\n",
        "    x = layers.BatchNormalization(name=prefix+'conv_bn')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "def AutoEncoder(input_shape):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    \n",
        "    # 256 x 256\n",
        "    conv1 = Conv2DLayer(inputs, 64, 3, strides=1, padding='same', block_id=1)\n",
        "    conv2 = Conv2DLayer(conv1, 64, 3, strides=2, padding='same', block_id=2)\n",
        "    \n",
        "    # 128 x 128\n",
        "    conv3 = Conv2DLayer(conv2, 128, 5, strides=2, padding='same', block_id=3)\n",
        "    \n",
        "    # 64 x 64\n",
        "    conv4 = Conv2DLayer(conv3, 128, 3, strides=1, padding='same', block_id=4)\n",
        "    conv5 = Conv2DLayer(conv4, 256, 5, strides=2, padding='same', block_id=5)\n",
        "    \n",
        "    # 32 x 32\n",
        "    conv6 = Conv2DLayer(conv5, 512, 3, strides=2, padding='same', block_id=6)\n",
        "    \n",
        "    # 16 x 16\n",
        "    deconv1 = Transpose_Conv2D(conv6, 512, 3, strides=2, padding='same', block_id=7)\n",
        "    \n",
        "    # 32 x 32\n",
        "    skip1 = layers.concatenate([deconv1, conv5], name='skip1')\n",
        "    conv7 = Conv2DLayer(skip1, 256, 3, strides=1, padding='same', block_id=8)\n",
        "    deconv2 = Transpose_Conv2D(conv7, 128, 3, strides=2, padding='same', block_id=9)\n",
        "    \n",
        "    # 64 x 64\n",
        "    skip2 = layers.concatenate([deconv2, conv3], name='skip2')\n",
        "    conv8 = Conv2DLayer(skip2, 128, 5, strides=1, padding='same', block_id=10)\n",
        "    deconv3 = Transpose_Conv2D(conv8, 64, 3, strides=2, padding='same', block_id=11)\n",
        "    \n",
        "    # 128 x 128\n",
        "    skip3 = layers.concatenate([deconv3, conv2], name='skip3')\n",
        "    conv9 = Conv2DLayer(skip3, 64, 5, strides=1, padding='same', block_id=12)\n",
        "    deconv4 = Transpose_Conv2D(conv9, 64, 3, strides=2, padding='same', block_id=13)\n",
        "    \n",
        "    # 256 x 256\n",
        "    skip3 = layers.concatenate([deconv4, conv1])\n",
        "    conv10 = layers.Conv2D(3, 3, strides=1, padding='same', activation='sigmoid',\n",
        "                       kernel_initializer=orthogonal(), name='final_conv')(skip3)\n",
        "\n",
        "    \n",
        "    return models.Model(inputs=inputs, outputs=conv10)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUkfFm5w2iis"
      },
      "source": [
        "# RUN only for train the autoenc\n",
        "autoencoder = AutoEncoder((*img_size, 3))\n",
        "model_opt = Adam(lr=0.002)\n",
        "\n",
        "autoencoder.compile(optimizer=model_opt, loss='mse', metrics=['accuracy'])\n",
        "#autoencoder.summary()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7sT-cwsh8_Z"
      },
      "source": [
        "# RUN only for train the autoenc\n",
        "saved_weight = os.path.join('/content/drive/MyDrive','saved_models_chall3', 'dataweights.{epoch:02d}.hdf5')\n",
        "modelchk = tf.keras.callbacks.ModelCheckpoint(saved_weight,\n",
        "                                              monitor='val_loss',\n",
        "                                              verbose=1,\n",
        "                                              save_best_only=True,\n",
        "                                              save_weights_only=False\n",
        "                                              )\n",
        "\n",
        "tensorboard = tf.keras.callbacks.TensorBoard(log_dir='logs',\n",
        "                                          histogram_freq=0,\n",
        "                                          write_graph=True,\n",
        "                                          write_images=True\n",
        "                                          )\n",
        "\n",
        "csv_logger = tf.keras.callbacks.CSVLogger('logs/keras_log.csv',\n",
        "                                       append=True)\n",
        "\n",
        "es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1, restore_best_weights=True)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96RbK1ADjEpD",
        "outputId": "bf5fef6a-af35-4a66-cb6a-da0fafa32729"
      },
      "source": [
        "# RUN only for train the autoenc\n",
        "epochs=50\n",
        "autoencoder.fit(train_data,\n",
        "                steps_per_epoch = len(train_data),\n",
        "                epochs=epochs,\n",
        "                verbose=1,\n",
        "                validation_data=valid_data,\n",
        "                validation_steps = len(train_data),\n",
        "                callbacks=[modelchk,tensorboard, csv_logger, es_callback]\n",
        "                )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qqBUvkCqKwd"
      },
      "source": [
        "autoencoder = tf.keras.models.load_model(os.path.join('/content/drive/MyDrive','saved_models_chall3', 'best_model_autoencoder.hdf5'))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%"
        },
        "id": "i-eKhRBjuRKM"
      },
      "source": [
        "def extract_layers(main_model, starting_layer_ix, ending_layer_ix):\n",
        "  # create an empty model\n",
        "  new_model = tf.keras.Sequential()\n",
        "  for ix in range(starting_layer_ix, ending_layer_ix + 1):\n",
        "    curr_layer = main_model.get_layer(index=ix)\n",
        "    # copy this layer over to the new model\n",
        "    new_model.add(curr_layer)\n",
        "  return new_model\n",
        "\n",
        "encoder = extract_layers(autoencoder, 0, 24)\n",
        "encoder.add(tf.keras.layers.GlobalAveragePooling2D())\n",
        "for l in encoder.layers:\n",
        "    l.trainable = False"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jljbz-9V-ySZ",
        "outputId": "4d38113a-ffbe-41fe-a804-2e7ec76684e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# RUN only for getting compressed feature\n",
        "\n",
        "train_images = set([el['image_id'] for el in data_train])\n",
        "valid_images = set([el['image_id'] for el in data_valid])\n",
        "len_train = len(train_images)\n",
        "len_valid = len(valid_images)\n",
        "\n",
        "print('taken the ' + str(len(valid_images)/len(train_images))+' of validation')\n",
        "i = 0\n",
        "train_tensor_map = {}\n",
        "for imagename in train_images:\n",
        "    print('{:3.2f} %'.format(i/len_valid * 100),end = '\\r')\n",
        "    image = Image.open(os.path.join(imagesPath, imagename + '.png')).resize(img_size).convert('RGB')\n",
        "    img = np.array(image).astype(np.float32) / 255\n",
        "    res = encoder.predict(x = np.expand_dims(img,0))\n",
        "    train_tensor_map[str(imagename)] = res.tolist()\n",
        "    i = i + 1\n",
        "\n",
        "json.dump(train_tensor_map, open(\"train_tensors_encoder.json\",\"w\"), indent=2)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "taken the 0.5738543939694505 of validation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcHjLtPNE52X",
        "outputId": "5683e979-97e8-43f7-cb9d-05bde4ce0843",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# RUN only for getting compressed feature\n",
        "\n",
        "valid_tensor_map = {}\n",
        "i = 0\n",
        "for imagename in valid_images:\n",
        "    print('{:3.2f} %'.format(i/len_valid * 100),end = '\\r')\n",
        "    image = Image.open(os.path.join(imagesPath, imagename + '.png')).resize(img_size).convert('RGB')\n",
        "    img = np.array(image).astype(np.float32) / 255\n",
        "    res = encoder.predict(x = np.expand_dims(img,0))\n",
        "    valid_tensor_map[str(imagename)] = res.tolist()\n",
        "    i = i + 1\n",
        "\n",
        "json.dump(valid_tensor_map, open(\"valid_tensors_encoder.json\",\"w\"), indent=2)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbcmI8h3E8UM"
      },
      "source": [
        "# RUN only for getting compressed feature\n",
        "\n",
        "test_images = set([el['image_id'] for el in data_test])\n",
        "\n",
        "len_test = len(test_images)\n",
        "test_tensor_map = {}\n",
        "i = 0\n",
        "for imagename in test_images:\n",
        "    print('{:3.2f} %'.format(i/len_valid * 100),end = '\\r')\n",
        "    image = Image.open(os.path.join(imagesPath, imagename + '.png')).resize(img_size).convert('RGB')\n",
        "    img = np.array(image).astype(np.float32) / 255\n",
        "    res = encoder.predict(x = np.expand_dims(img,0))\n",
        "    test_tensor_map[str(imagename)] = res.tolist()\n",
        "    i = i + 1\n",
        "\n",
        "json.dump(test_tensor_map, open(\"test_tensors_encoder.json\",\"w\"), indent=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLW1dlOnhcZ-"
      },
      "source": [
        "classes = {\n",
        "        '0': 0,\n",
        "        '1': 1,\n",
        "        '2': 2,\n",
        "        '3': 3,\n",
        "        '4': 4,\n",
        "        '5': 5,\n",
        "        'apple': 6,\n",
        "        'baseball': 7,\n",
        "        'bench': 8,\n",
        "        'bike': 9,\n",
        "        'bird': 10,\n",
        "        'black': 11,\n",
        "        'blanket': 12,\n",
        "        'blue': 13,\n",
        "        'bone': 14,\n",
        "        'book': 15,\n",
        "        'boy': 16,\n",
        "        'brown': 17,\n",
        "        'cat': 18,\n",
        "        'chair': 19,\n",
        "        'couch': 20,\n",
        "        'dog': 21,\n",
        "        'floor': 22,\n",
        "        'food': 23,\n",
        "        'football': 24,\n",
        "        'girl': 25,\n",
        "        'grass': 26,\n",
        "        'gray': 27,\n",
        "        'green': 28,\n",
        "        'left': 29,\n",
        "        'log': 30,\n",
        "        'man': 31,\n",
        "        'monkey bars': 32,\n",
        "        'no': 33,\n",
        "        'nothing': 34,\n",
        "        'orange': 35,\n",
        "        'pie': 36,\n",
        "        'plant': 37,\n",
        "        'playing': 38,\n",
        "        'red': 39,\n",
        "        'right': 40,\n",
        "        'rug': 41,\n",
        "        'sandbox': 42,\n",
        "        'sitting': 43,\n",
        "        'sleeping': 44,\n",
        "        'soccer': 45,\n",
        "        'squirrel': 46,\n",
        "        'standing': 47,\n",
        "        'stool': 48,\n",
        "        'sunny': 49,\n",
        "        'table': 50,\n",
        "        'tree': 51,\n",
        "        'watermelon': 52,\n",
        "        'white': 53,\n",
        "        'wine': 54,\n",
        "        'woman': 55,\n",
        "        'yellow': 56,\n",
        "        'yes': 57\n",
        "}\n",
        "\n",
        "bst= 150\n",
        "bsv= 150"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Gqc__QujL-J"
      },
      "source": [
        "class CustomDataGenerator(tf.keras.utils.Sequence):\n",
        "\n",
        "    def __init__(self, data, batch_size, tokenizer, featuresMap, maxSentenceLen, seed=96, num_classes=58, shuffle=True, test=False):\n",
        "        self.data = data  # data on wich perform\n",
        "        self.batch_size = batch_size  # batch size\n",
        "        self.featuresMap = featuresMap  # features of the images obtained from a pretrained model\n",
        "        self.seed = seed  # seed for the shuffle operations\n",
        "        self.num_classes = num_classes  # number of classes (13 in our case)\n",
        "        self.test = test\n",
        "        self.shuffle = shuffle # boolean to say if to perform shuffle on each batch or not\n",
        "        self.on_epoch_end()  \n",
        "        self.tok = tokenizer\n",
        "        self.maxSentenceLen = maxSentenceLen\n",
        "        # set the seed\n",
        "        random.seed(self.seed)\n",
        "        np.random.seed(self.seed)\n",
        "\n",
        "    def __len__(self):\n",
        "        'method for the lenght of the generator'\n",
        "        return int(np.floor(len(self.data) / self.batch_size))\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(len(self.data))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'returns a batch of (image, question) and answer'\n",
        "        indexes = self.indexes[index * self.batch_size: (index + 1) * self.batch_size]\n",
        "        data_temp = [self.data[k] for k in indexes]\n",
        "        X = self._generate_X(data_temp)\n",
        "        if self.test == False:\n",
        "            y = self._generate_y(data_temp)\n",
        "            return X, y\n",
        "        else:\n",
        "            return X\n",
        "\n",
        "    def _generate_X(self, data_temp):\n",
        "        'generates the batch of (image,question)'\n",
        "        img_array = np.empty((self.batch_size, 512))\n",
        "        question_array = np.empty((self.batch_size, self.maxSentenceLen))\n",
        "        for i, dictionary in enumerate(data_temp):\n",
        "            filename = dictionary['image_id']\n",
        "            image = np.array(self.featuresMap[filename])\n",
        "            img_array[i,] = image.squeeze()\n",
        "            token = self.tok.texts_to_sequences([dictionary['question']])\n",
        "            padded_sequence = tf.keras.preprocessing.sequence.pad_sequences(token, maxlen=self.maxSentenceLen)\n",
        "            padded_sequence = padded_sequence.squeeze()\n",
        "            question_array[i,] = padded_sequence\n",
        "        x1 = np.array(img_array)\n",
        "        x2 = np.array(question_array)\n",
        "        return [x1, x2]\n",
        "\n",
        "    def _generate_y(self, data_temp):\n",
        "        'generates the one hot encoding of the answer'\n",
        "        answer_array = []\n",
        "        for dictionary in data_temp:\n",
        "            answer_array.append(\n",
        "                tf.keras.utils.to_categorical(classes[dictionary['answer']], num_classes=self.num_classes))\n",
        "        y = np.array(answer_array)\n",
        "        return y"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AkZrnM9yczH"
      },
      "source": [
        "trainTensors = os.path.join(datasetName, \"train_tensors_encoder.json\")\n",
        "validTensors = os.path.join(datasetName, \"valid_tensors_encoder.json\")\n",
        "\n",
        "with open(trainJsonPath,'r') as json_file_train, open (validJsonPath, 'r') as json_file_valid:\n",
        "    data_train = json.load(json_file_train)\n",
        "    data_valid = json.load(json_file_valid)\n",
        "    json_file_train.close()\n",
        "    json_file_valid.close()\n",
        "\n",
        "train_size = len(data_train)\n",
        "valid_size = len(data_valid)\n",
        "\n",
        "with open(trainTensors,'r') as json_file_train, open (validTensors, 'r') as json_file_valid:\n",
        "    train_features = json.load(json_file_train)\n",
        "    valid_features = json.load(json_file_valid)\n",
        "    json_file_train.close()\n",
        "    json_file_valid.close()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LdyOl1Nk13R"
      },
      "source": [
        "questions = [el['question'] for el in data_train]\n",
        "words = set()\n",
        "maxLength = 0\n",
        "for q in questions:\n",
        "    seq = tf.keras.preprocessing.text.text_to_word_sequence(q)\n",
        "    if maxLength < len(seq): maxLength = len(seq)\n",
        "    for x in seq:\n",
        "        words.add(x)\n",
        "# number of different words in our sequences or vocaboulary size\n",
        "n_words = len(words)\n",
        "# Tokenizer and indexes creation\n",
        "tok = tf.keras.preprocessing.text.Tokenizer(num_words=n_words)\n",
        "tok.fit_on_texts(questions)\n",
        "\n",
        "gen_train = CustomDataGenerator(data_train, bst, tok, train_features, maxSentenceLen=n_words)\n",
        "gen_val   = CustomDataGenerator(data_valid, bsv, tok, valid_features, shuffle = False, maxSentenceLen=n_words)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YJ2CcdwliOU",
        "outputId": "1119b5ed-804f-4d9f-bf1e-87742f896cc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Structure of the CNN and of the RNN\n",
        "\n",
        "#CNN\n",
        "inp1 = tf.keras.Input(shape = (512))\n",
        "\n",
        "dense1 = tf.keras.layers.Dense(units=256, activation= tf.keras.activations.relu, kernel_initializer = 'he_uniform')(inp1)\n",
        "\n",
        "#RNN with LSTM\n",
        "inp2 = tf.keras.Input(name='input_LSTM', shape=(maxLength-1))\n",
        "r = tf.keras.layers.Embedding(input_dim=n_words, output_dim=32)(inp2)\n",
        "r = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=256, return_sequences=True))(r)\n",
        "r = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=256, return_sequences=False))(r)\n",
        "dense2 = tf.keras.layers.Dense(units=256, activation = tf.keras.activations.relu, kernel_initializer = 'he_uniform')(r)\n",
        "\n",
        "conc = tf.keras.layers.Concatenate()([dense1, dense2])\n",
        "d = tf.keras.layers.Dense(units=1024, activation=tf.keras.activations.relu, kernel_initializer = 'he_uniform')(conc)\n",
        "d = tf.keras.layers.Dropout(0.3)(d)\n",
        "d = tf.keras.layers.Dense(units=1024, activation=tf.keras.activations.relu, kernel_initializer = 'he_uniform')(d)\n",
        "d = tf.keras.layers.Dropout(0.3)(d)\n",
        "out = tf.keras.layers.Dense(units=13, activation=tf.keras.activations.softmax)(d)\n",
        "\n",
        "model = tf.keras.Model([inp1, inp2], out)\n",
        "model.summary()\n",
        "\n",
        "loss = tf.keras.losses.CategoricalCrossentropy()\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-3)\n",
        "metrics = ['accuracy']\n",
        "saved_weight = os.path.join('/content/drive/MyDrive','saved_models_chall3', 'model_{epoch:02d}.hdf5')\n",
        "model_chk = tf.keras.callbacks.ModelCheckpoint(saved_weight,\n",
        "                                              monitor='val_loss',\n",
        "                                              verbose=1,\n",
        "                                              save_best_only=True,\n",
        "                                              save_weights_only=False\n",
        "                                              )\n",
        "\n",
        "model.compile(metrics=metrics, optimizer=optimizer, loss=loss)\n",
        "\n",
        "model.fit(gen_train, steps_per_epoch=len(gen_train), \n",
        "                    validation_data=gen_val, validation_steps=len(gen_val),\n",
        "                    epochs = 10, callbacks = [model_chk])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_LSTM (InputLayer)         [(None, 20)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 20, 32)       128256      input_LSTM[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   (None, 20, 512)      591872      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_1 (InputLayer)            [(None, 512)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) (None, 512)          1574912     bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 256)          131328      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 256)          131328      bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 512)          0           dense[0][0]                      \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1024)         525312      concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 1024)         0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 1024)         1049600     dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 1024)         0           dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 13)           13325       dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 4,145,933\n",
            "Trainable params: 4,145,933\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "CancelledError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-25f5139d5573>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m model.fit(gen_train, steps_per_epoch=len(gen_train), \n\u001b[1;32m     39\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgen_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                     epochs = 10, callbacks = [model_chk])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mCancelledError\u001b[0m:  [_Derived_]RecvAsync is cancelled.\n\t [[{{node gradient_tape/model/embedding/embedding_lookup/Reshape/_34}}]] [Op:__inference_train_function_13181]\n\nFunction call stack:\ntrain_function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQ_Ucwekocqr"
      },
      "source": [
        "def create_csv(results, results_dir='./'):\n",
        "    csv_fname = 'results_'\n",
        "    csv_fname += datetime.now().strftime('%b%d_%H-%M-%S') + '.csv'\n",
        "    with open(os.path.join(results_dir, csv_fname), 'w') as f:\n",
        "        f.write('Id,Category\\n')\n",
        "        for key, value in results.items():\n",
        "            f.write(str(key) + ',' + str(value) + '\\n')\n",
        "\n",
        "testJsonName = 'test.json'\n",
        "testJsonPath = os.path.join(datasetName, testJsonName)\n",
        "\n",
        "testTensors = os.path.join(tensors, \"test_tensors_encoders.json\")\n",
        "\n",
        "with open(testJsonPath,'r') as json_file_test:\n",
        "    data_test = json.load(json_file_test).get('questions')\n",
        "    json_file_test.close()\n",
        "\n",
        "with open(testTensors,'r') as json_file_test:\n",
        "    test_features = json.load(json_file_test)\n",
        "    json_file_test.close()\n",
        "\n",
        "print('Test set length:' + str(len(data_test)))\n",
        "test_gen = CustomDataGenerator(data_test, 1, tok, test_features, \n",
        "                               shuffle=False, test=True)\n",
        "\n",
        "predictions = model.predict_generator(test_gen)\n",
        "print('Predictions vector length:' + str(len(predictions)))\n",
        "\n",
        "results = {}\n",
        "\n",
        "work_pr = []\n",
        "for i in range(len(predictions)):\n",
        "    work_pr.append(tf.argmax(predictions[i], axis=-1).numpy())\n",
        "\n",
        "for i in range(len(data_test)):\n",
        "    results[data_test[i].get('question_id')] = work_pr[i]\n",
        "\n",
        "create_csv(results)\n",
        "print('CSV written!')\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}