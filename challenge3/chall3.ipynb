{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chall3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "lRO-dwZJuRKA"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicologhielmetti/AN2DL-challenges/blob/master/challenge3/chall3.ipynb\" target=\"_parent\">\n",
        "    <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZpmn88cRoE8"
      },
      "source": [
        "import json, os\n",
        "from functools import partial\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import keras.layers as layers\n",
        "import keras.models as models\n",
        "from keras.initializers import orthogonal\n",
        "from keras.optimizers import Adam\n",
        "import shutil\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from datetime import datetime"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxKfWGwf5FII",
        "outputId": "51e4cbcf-0b69-4f78-d667-02f7aaff813d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlhygyiVnN7-"
      },
      "source": [
        "#!pip install gdown\n",
        "#!gdown https://drive.google.com/uc?id=1tglwr5cbQbzrSLmJlHmz33htFUw0yzc4\n",
        "!unzip -qq /content/drive/MyDrive/anndl-2020-vqa.zip -d \"/content/drive/MyDrive/\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "0JQ6LsaZuRKH"
      },
      "source": [
        "#!unzip -qq VQA_Dataset.zip -d VQA_Dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xK7JXN60ien"
      },
      "source": [
        "random.seed(96)\n",
        "\n",
        "cwd = os.getcwd()\n",
        "\n",
        "datasetName = os.path.join(cwd,'drive/MyDrive/VQA_Dataset')\n",
        "trainJsonName = 'train.json'\n",
        "validJsonName = 'valid.json'\n",
        "testJsonName  = 'test_questions.json'\n",
        "testJsonNameCorrect = 'test.json'\n",
        "imagesPath = os.path.join(datasetName, 'Images')\n",
        "trainJsonPath = os.path.join(datasetName, trainJsonName)\n",
        "validJsonPath = os.path.join(datasetName, validJsonName)\n",
        "testJsonPath  = os.path.join(datasetName, testJsonName)\n",
        "testJsonPathCorrect  = os.path.join(datasetName, testJsonNameCorrect)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siaKwgfhgtOk"
      },
      "source": [
        "def create_split_files(file_path, train_val_split):\n",
        "    with open(file_path,'r') as json_dataset:\n",
        "        data = json.load(json_dataset)\n",
        "\n",
        "    tot_list = list()\n",
        "    for k,v in data.items():\n",
        "        tot_list.append(v)\n",
        "\n",
        "    train_list = random.sample(tot_list, int(len(tot_list) * (1 - train_val_split)))\n",
        "    validation_list = [i for i in tot_list if i not in train_list]\n",
        "\n",
        "    with open(\"drive/MyDrive/VQA_Dataset/train.json\", \"w\") as train:\n",
        "        json.dump(train_list, train)\n",
        "        train.close()\n",
        "    with open(\"drive/MyDrive/VQA_Dataset/valid.json\", \"w\") as validation:\n",
        "        json.dump(validation_list, validation)\n",
        "        validation.close()\n",
        "    \n",
        "    #assert len([x for x in tot_list if x in train_list and x in validation_list]) == 0\n",
        "\n",
        "def generate_correct_test_file(testJsonPath):\n",
        "    with open(testJsonPath,'r') as json_dataset:\n",
        "        data = json.load(json_dataset)\n",
        "\n",
        "    test_list = list()\n",
        "    for k,v in data.items():\n",
        "        v[\"question_id\"] = k\n",
        "        test_list.append(v)\n",
        "\n",
        "    with open(\"drive/MyDrive/VQA_Dataset/test.json\", \"w\") as test:\n",
        "        json.dump(test_list, test)\n",
        "        test.close()\n",
        "\n",
        "def create_train_test_dirs(json_definition, dataset_path, split_name):\n",
        "    dest_dir = os.path.join(dataset_path, split_name)\n",
        "    if not os.path.isdir(dest_dir):\n",
        "      os.mkdir(dest_dir)\n",
        "      os.mkdir(os.path.join(dest_dir, split_name))\n",
        "    for k,v in json_definition.items():\n",
        "        try:\n",
        "            shutil.copy(\n",
        "                os.path.join(dataset_path, \"Images\", k +'.png'),\n",
        "                os.path.join(dest_dir, split_name, k +'.png')\n",
        "            )\n",
        "        except FileNotFoundError as e:\n",
        "            print(\"Split name: \" + split_name + \". File not found: \" + str(e))\n",
        "            continue\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2cUoc7RBo8J"
      },
      "source": [
        "\n",
        "create_split_files(os.path.join(datasetName, 'train_questions_annotations.json'), 0.3)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUL3ADwMNMmB"
      },
      "source": [
        "generate_correct_test_file(testJsonPath)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MRoHGbaRwCD"
      },
      "source": [
        "\n",
        "\n",
        "with open(trainJsonPath,'r') as json_file_train, open(validJsonPath, 'r') as json_file_valid, open(testJsonPathCorrect, 'r') as json_file_test:\n",
        "    data_train = json.load(json_file_train)\n",
        "    data_valid = json.load(json_file_valid)\n",
        "    data_test = json.load(json_file_test)\n",
        "\n",
        "    json_file_train.close()\n",
        "    json_file_valid.close()\n",
        "    json_file_test.close()\n",
        "\n",
        "\n",
        "os.chdir(cwd)\n",
        "#create_train_test_dirs(data_train, datasetName, 'train')\n",
        "#create_train_test_dirs(data_valid, datasetName, 'validation')\n",
        "#create_train_test_dirs(data_test, datasetName, 'test')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "F2sbKp0cuRKI"
      },
      "source": [
        "# RUN only for train the autoenc\n",
        "dest_dir = os.path.join(datasetName, \"ImagesExt\")\n",
        "if not os.path.isdir(dest_dir):\n",
        "  os.mkdir(dest_dir)\n",
        "shutil.move(imagesPath, dest_dir)\n",
        "imagesPath = os.path.join(dest_dir, \"Images\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPOeAGuUuRKJ",
        "outputId": "4e7bf419-6325-49d9-c8f6-f1012582833c"
      },
      "source": [
        "# RUN only for train the autoenc\n",
        "img_size = (256, 256)\n",
        "preproc_fun_fixed = partial(tf.keras.preprocessing.image.smart_resize, size=img_size)\n",
        "batch_size = 32\n",
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,\n",
        "                                                          data_format='channels_last',\n",
        "                                                          preprocessing_function=preproc_fun_fixed,\n",
        "                                                          validation_split=0.3)\n",
        "train_data = datagen.flow_from_directory(datasetName+'/ImagesExt', img_size, class_mode='input',\n",
        "                                         batch_size=batch_size, subset=\"training\")\n",
        "valid_data = datagen.flow_from_directory(datasetName+'/ImagesExt', img_size, class_mode='input',\n",
        "                                         batch_size=batch_size, subset=\"validation\")\n",
        "\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 20534 images belonging to 1 classes.\n",
            "Found 8799 images belonging to 1 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUWJZpBuSYBJ"
      },
      "source": [
        "# RUN only for train the autoenc\n",
        "def Conv2DLayer(x, filters, kernel, strides, padding, block_id, kernel_init=orthogonal()):\n",
        "    prefix = f'block_{block_id}_'\n",
        "    x = layers.Conv2D(filters, kernel_size=kernel, strides=strides, padding=padding,\n",
        "                      kernel_initializer=kernel_init, name=prefix+'conv')(x)\n",
        "    x = layers.LeakyReLU(name=prefix+'lrelu')(x)\n",
        "    x = layers.Dropout(0.2, name=prefix+'drop')((x))\n",
        "    x = layers.BatchNormalization(name=prefix+'conv_bn')(x)\n",
        "    return x\n",
        "\n",
        "def Transpose_Conv2D(x, filters, kernel, strides, padding, block_id, kernel_init=orthogonal()):\n",
        "    prefix = f'block_{block_id}_'\n",
        "    x = layers.Conv2DTranspose(filters, kernel_size=kernel, strides=strides, padding=padding,\n",
        "                               kernel_initializer=kernel_init, name=prefix+'de-conv')(x)\n",
        "    x = layers.LeakyReLU(name=prefix+'lrelu')(x)\n",
        "    x = layers.Dropout(0.2, name=prefix+'drop')((x))\n",
        "    x = layers.BatchNormalization(name=prefix+'conv_bn')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "def AutoEncoder(input_shape):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    \n",
        "    # 256 x 256\n",
        "    conv1 = Conv2DLayer(inputs, 64, 3, strides=1, padding='same', block_id=1)\n",
        "    conv2 = Conv2DLayer(conv1, 64, 3, strides=2, padding='same', block_id=2)\n",
        "    \n",
        "    # 128 x 128\n",
        "    conv3 = Conv2DLayer(conv2, 128, 5, strides=2, padding='same', block_id=3)\n",
        "    \n",
        "    # 64 x 64\n",
        "    conv4 = Conv2DLayer(conv3, 128, 3, strides=1, padding='same', block_id=4)\n",
        "    conv5 = Conv2DLayer(conv4, 256, 5, strides=2, padding='same', block_id=5)\n",
        "    \n",
        "    # 32 x 32\n",
        "    conv6 = Conv2DLayer(conv5, 512, 3, strides=2, padding='same', block_id=6)\n",
        "    \n",
        "    # 16 x 16\n",
        "    deconv1 = Transpose_Conv2D(conv6, 512, 3, strides=2, padding='same', block_id=7)\n",
        "    \n",
        "    # 32 x 32\n",
        "    skip1 = layers.concatenate([deconv1, conv5], name='skip1')\n",
        "    conv7 = Conv2DLayer(skip1, 256, 3, strides=1, padding='same', block_id=8)\n",
        "    deconv2 = Transpose_Conv2D(conv7, 128, 3, strides=2, padding='same', block_id=9)\n",
        "    \n",
        "    # 64 x 64\n",
        "    skip2 = layers.concatenate([deconv2, conv3], name='skip2')\n",
        "    conv8 = Conv2DLayer(skip2, 128, 5, strides=1, padding='same', block_id=10)\n",
        "    deconv3 = Transpose_Conv2D(conv8, 64, 3, strides=2, padding='same', block_id=11)\n",
        "    \n",
        "    # 128 x 128\n",
        "    skip3 = layers.concatenate([deconv3, conv2], name='skip3')\n",
        "    conv9 = Conv2DLayer(skip3, 64, 5, strides=1, padding='same', block_id=12)\n",
        "    deconv4 = Transpose_Conv2D(conv9, 64, 3, strides=2, padding='same', block_id=13)\n",
        "    \n",
        "    # 256 x 256\n",
        "    skip3 = layers.concatenate([deconv4, conv1])\n",
        "    conv10 = layers.Conv2D(3, 3, strides=1, padding='same', activation='sigmoid',\n",
        "                       kernel_initializer=orthogonal(), name='final_conv')(skip3)\n",
        "\n",
        "    \n",
        "    return models.Model(inputs=inputs, outputs=conv10)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUkfFm5w2iis"
      },
      "source": [
        "# RUN only for train the autoenc\n",
        "autoencoder = AutoEncoder((*img_size, 3))\n",
        "model_opt = Adam(lr=0.002)\n",
        "\n",
        "autoencoder.compile(optimizer=model_opt, loss='mse', metrics=['accuracy'])\n",
        "#autoencoder.summary()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7sT-cwsh8_Z"
      },
      "source": [
        "# RUN only for train the autoenc\n",
        "saved_weight = os.path.join('/content/drive/MyDrive','saved_models_chall3', 'dataweights.{epoch:02d}.hdf5')\n",
        "modelchk = tf.keras.callbacks.ModelCheckpoint(saved_weight,\n",
        "                                              monitor='val_loss',\n",
        "                                              verbose=1,\n",
        "                                              save_best_only=True,\n",
        "                                              save_weights_only=False\n",
        "                                              )\n",
        "\n",
        "tensorboard = tf.keras.callbacks.TensorBoard(log_dir='logs',\n",
        "                                          histogram_freq=0,\n",
        "                                          write_graph=True,\n",
        "                                          write_images=True\n",
        "                                          )\n",
        "\n",
        "csv_logger = tf.keras.callbacks.CSVLogger('logs/keras_log.csv',\n",
        "                                       append=True)\n",
        "\n",
        "es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1, restore_best_weights=True)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96RbK1ADjEpD",
        "outputId": "bf5fef6a-af35-4a66-cb6a-da0fafa32729"
      },
      "source": [
        "# RUN only for train the autoenc\n",
        "epochs=50\n",
        "autoencoder.fit(train_data,\n",
        "                steps_per_epoch = len(train_data),\n",
        "                epochs=epochs,\n",
        "                verbose=1,\n",
        "                validation_data=valid_data,\n",
        "                validation_steps = len(train_data),\n",
        "                callbacks=[modelchk,tensorboard, csv_logger, es_callback]\n",
        "                )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qqBUvkCqKwd"
      },
      "source": [
        "autoencoder = tf.keras.models.load_model(os.path.join('/content/drive/MyDrive','saved_models_chall3', 'best_model_autoencoder.hdf5'))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%"
        },
        "id": "i-eKhRBjuRKM"
      },
      "source": [
        "# RUN only for getting compressed feature\n",
        "\n",
        "def extract_layers(main_model, starting_layer_ix, ending_layer_ix):\n",
        "  # create an empty model\n",
        "  new_model = tf.keras.Sequential()\n",
        "  for ix in range(starting_layer_ix, ending_layer_ix + 1):\n",
        "    curr_layer = main_model.get_layer(index=ix)\n",
        "    # copy this layer over to the new model\n",
        "    new_model.add(curr_layer)\n",
        "  return new_model\n",
        "\n",
        "encoder = extract_layers(autoencoder, 0, 24)\n",
        "encoder.add(tf.keras.layers.GlobalAveragePooling2D())\n",
        "for l in encoder.layers:\n",
        "    l.trainable = False"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jljbz-9V-ySZ",
        "outputId": "4d38113a-ffbe-41fe-a804-2e7ec76684e6"
      },
      "source": [
        "# RUN only for getting compressed feature\n",
        "\n",
        "train_images = set([el['image_id'] for el in data_train])\n",
        "valid_images = set([el['image_id'] for el in data_valid])\n",
        "len_train = len(train_images)\n",
        "len_valid = len(valid_images)\n",
        "\n",
        "print('taken the ' + str(len(valid_images)/len(train_images))+' of validation')\n",
        "i = 0\n",
        "train_tensor_map = {}\n",
        "for imagename in train_images:\n",
        "    print('{:3.2f} %'.format(i/len_valid * 100),end = '\\r')\n",
        "    image = Image.open(os.path.join(imagesPath, imagename + '.png')).resize(img_size).convert('RGB')\n",
        "    img = np.array(image).astype(np.float32) / 255\n",
        "    res = encoder.predict(x = np.expand_dims(img,0))\n",
        "    train_tensor_map[str(imagename)] = res.tolist()\n",
        "    i = i + 1\n",
        "\n",
        "json.dump(train_tensor_map, open(\"train_tensors_encoder.json\",\"w\"), indent=2)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "taken the 0.5738543939694505 of validation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcHjLtPNE52X",
        "outputId": "5683e979-97e8-43f7-cb9d-05bde4ce0843"
      },
      "source": [
        "# RUN only for getting compressed feature\n",
        "\n",
        "valid_tensor_map = {}\n",
        "i = 0\n",
        "for imagename in valid_images:\n",
        "    print('{:3.2f} %'.format(i/len_valid * 100),end = '\\r')\n",
        "    image = Image.open(os.path.join(imagesPath, imagename + '.png')).resize(img_size).convert('RGB')\n",
        "    img = np.array(image).astype(np.float32) / 255\n",
        "    res = encoder.predict(x = np.expand_dims(img,0))\n",
        "    valid_tensor_map[str(imagename)] = res.tolist()\n",
        "    i = i + 1\n",
        "\n",
        "json.dump(valid_tensor_map, open(\"valid_tensors_encoder.json\",\"w\"), indent=2)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbcmI8h3E8UM"
      },
      "source": [
        "# RUN only for getting compressed feature\n",
        "\n",
        "test_images = set([el['image_id'] for el in data_test])\n",
        "\n",
        "len_test = len(test_images)\n",
        "test_tensor_map = {}\n",
        "i = 0\n",
        "for imagename in test_images:\n",
        "    print('{:3.2f} %'.format(i/len_valid * 100),end = '\\r')\n",
        "    image = Image.open(os.path.join(imagesPath, imagename + '.png')).resize(img_size).convert('RGB')\n",
        "    img = np.array(image).astype(np.float32) / 255\n",
        "    res = encoder.predict(x = np.expand_dims(img,0))\n",
        "    test_tensor_map[str(imagename)] = res.tolist()\n",
        "    i = i + 1\n",
        "\n",
        "json.dump(test_tensor_map, open(\"test_tensors_encoder.json\",\"w\"), indent=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLW1dlOnhcZ-"
      },
      "source": [
        "classes = {\n",
        "        '0': 0,\n",
        "        '1': 1,\n",
        "        '2': 2,\n",
        "        '3': 3,\n",
        "        '4': 4,\n",
        "        '5': 5,\n",
        "        'apple': 6,\n",
        "        'baseball': 7,\n",
        "        'bench': 8,\n",
        "        'bike': 9,\n",
        "        'bird': 10,\n",
        "        'black': 11,\n",
        "        'blanket': 12,\n",
        "        'blue': 13,\n",
        "        'bone': 14,\n",
        "        'book': 15,\n",
        "        'boy': 16,\n",
        "        'brown': 17,\n",
        "        'cat': 18,\n",
        "        'chair': 19,\n",
        "        'couch': 20,\n",
        "        'dog': 21,\n",
        "        'floor': 22,\n",
        "        'food': 23,\n",
        "        'football': 24,\n",
        "        'girl': 25,\n",
        "        'grass': 26,\n",
        "        'gray': 27,\n",
        "        'green': 28,\n",
        "        'left': 29,\n",
        "        'log': 30,\n",
        "        'man': 31,\n",
        "        'monkey bars': 32,\n",
        "        'no': 33,\n",
        "        'nothing': 34,\n",
        "        'orange': 35,\n",
        "        'pie': 36,\n",
        "        'plant': 37,\n",
        "        'playing': 38,\n",
        "        'red': 39,\n",
        "        'right': 40,\n",
        "        'rug': 41,\n",
        "        'sandbox': 42,\n",
        "        'sitting': 43,\n",
        "        'sleeping': 44,\n",
        "        'soccer': 45,\n",
        "        'squirrel': 46,\n",
        "        'standing': 47,\n",
        "        'stool': 48,\n",
        "        'sunny': 49,\n",
        "        'table': 50,\n",
        "        'tree': 51,\n",
        "        'watermelon': 52,\n",
        "        'white': 53,\n",
        "        'wine': 54,\n",
        "        'woman': 55,\n",
        "        'yellow': 56,\n",
        "        'yes': 57\n",
        "}\n",
        "\n",
        "bst= 300\n",
        "bsv= 300"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Gqc__QujL-J"
      },
      "source": [
        "class CustomDataGenerator(tf.keras.utils.Sequence):\n",
        "\n",
        "    def __init__(self, data, batch_size, tokenizer, featuresMap, maxSentenceLen, seed=96, num_classes=58, shuffle=True, test=False):\n",
        "        self.data = data  # data on wich perform\n",
        "        self.batch_size = batch_size  # batch size\n",
        "        self.featuresMap = featuresMap  # features of the images obtained from a pretrained model\n",
        "        self.seed = seed  # seed for the shuffle operations\n",
        "        self.num_classes = num_classes  # number of classes (13 in our case)\n",
        "        self.test = test\n",
        "        self.shuffle = shuffle # boolean to say if to perform shuffle on each batch or not\n",
        "        self.on_epoch_end()  \n",
        "        self.tok = tokenizer\n",
        "        self.maxSentenceLen = maxSentenceLen\n",
        "        # set the seed\n",
        "        random.seed(self.seed)\n",
        "        np.random.seed(self.seed)\n",
        "\n",
        "    def __len__(self):\n",
        "        'method for the lenght of the generator'\n",
        "        return int(np.floor(len(self.data) / self.batch_size))\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(len(self.data))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'returns a batch of (image, question) and answer'\n",
        "        indexes = self.indexes[index * self.batch_size: (index + 1) * self.batch_size]\n",
        "        data_temp = [self.data[k] for k in indexes]\n",
        "        X = self._generate_X(data_temp)\n",
        "        if self.test == False:\n",
        "            y = self._generate_y(data_temp)\n",
        "            return X, y\n",
        "        else:\n",
        "            return X\n",
        "\n",
        "    def _generate_X(self, data_temp):\n",
        "        'generates the batch of (image,question)'\n",
        "        img_array = np.empty((self.batch_size, 512))\n",
        "        question_array = np.empty((self.batch_size, self.maxSentenceLen))\n",
        "        for i, dictionary in enumerate(data_temp):\n",
        "            filename = dictionary['image_id']\n",
        "            image = np.array(self.featuresMap[filename])\n",
        "            img_array[i,] = image.squeeze()\n",
        "            token = self.tok.texts_to_sequences([dictionary['question']])\n",
        "            padded_sequence = tf.keras.preprocessing.sequence.pad_sequences(token, maxlen=self.maxSentenceLen)\n",
        "            padded_sequence = padded_sequence.squeeze()\n",
        "            question_array[i,] = padded_sequence\n",
        "        x1 = np.array(img_array)\n",
        "        x2 = np.array(question_array)\n",
        "        return [x1, x2]\n",
        "\n",
        "    def _generate_y(self, data_temp):\n",
        "        'generates the one hot encoding of the answer'\n",
        "        answer_array = []\n",
        "        for dictionary in data_temp:\n",
        "            answer_array.append(\n",
        "                tf.keras.utils.to_categorical(classes[dictionary['answer']], num_classes=self.num_classes))\n",
        "        y = np.array(answer_array)\n",
        "        return y"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AkZrnM9yczH"
      },
      "source": [
        "trainTensors = os.path.join(datasetName, \"train_tensors_encoder.json\")\n",
        "validTensors = os.path.join(datasetName, \"valid_tensors_encoder.json\")\n",
        "\n",
        "with open(trainJsonPath,'r') as json_file_train, open (validJsonPath, 'r') as json_file_valid:\n",
        "    data_train = json.load(json_file_train)\n",
        "    data_valid = json.load(json_file_valid)\n",
        "    json_file_train.close()\n",
        "    json_file_valid.close()\n",
        "\n",
        "train_size = len(data_train)\n",
        "valid_size = len(data_valid)\n",
        "\n",
        "with open(trainTensors,'r') as json_file_train, open (validTensors, 'r') as json_file_valid:\n",
        "    train_features = json.load(json_file_train)\n",
        "    valid_features = json.load(json_file_valid)\n",
        "    json_file_train.close()\n",
        "    json_file_valid.close()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LdyOl1Nk13R"
      },
      "source": [
        "questions = [el['question'] for el in data_train]\n",
        "words = set()\n",
        "maxLength = 0\n",
        "for q in questions:\n",
        "    seq = tf.keras.preprocessing.text.text_to_word_sequence(q)\n",
        "    if maxLength < len(seq): maxLength = len(seq)\n",
        "    for x in seq:\n",
        "        words.add(x)\n",
        "# number of different words in our sequences or vocaboulary size\n",
        "n_words = len(words)\n",
        "# Tokenizer and indexes creation\n",
        "tok = tf.keras.preprocessing.text.Tokenizer(num_words=n_words)\n",
        "tok.fit_on_texts(questions)\n",
        "\n",
        "gen_train = CustomDataGenerator(data_train, bst, tok, train_features, maxSentenceLen=maxLength)\n",
        "gen_val   = CustomDataGenerator(data_valid, bsv, tok, valid_features, shuffle = False, maxSentenceLen=maxLength)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7513rQgFDtS3"
      },
      "source": [
        "#Structure of the CNN and of the RNN\n",
        "\n",
        "#CNN\n",
        "inp1 = tf.keras.Input(shape = (512))\n",
        "\n",
        "dense1 = tf.keras.layers.Dense(units=256, activation= tf.keras.activations.relu, kernel_initializer = 'he_uniform')(inp1)\n",
        "\n",
        "#RNN with LSTM\n",
        "inp2 = tf.keras.Input(name='input_LSTM', shape=maxLength)\n",
        "r = tf.keras.layers.Embedding(input_dim=n_words, output_dim=32)(inp2)\n",
        "r = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=256, return_sequences=True))(r)\n",
        "r = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=256, return_sequences=False))(r)\n",
        "dense2 = tf.keras.layers.Dense(units=256, activation = tf.keras.activations.relu, kernel_initializer = 'he_uniform')(r)\n",
        "\n",
        "conc = tf.keras.layers.Concatenate()([dense1, dense2])\n",
        "d = tf.keras.layers.Dense(units=1024, activation=tf.keras.activations.relu, kernel_initializer = 'he_uniform')(conc)\n",
        "d = tf.keras.layers.Dropout(0.2)(d)\n",
        "d = tf.keras.layers.Dense(units=1024, activation=tf.keras.activations.relu, kernel_initializer = 'he_uniform')(d)\n",
        "d = tf.keras.layers.Dropout(0.2)(d)\n",
        "out = tf.keras.layers.Dense(units=58, activation=tf.keras.activations.softmax)(d)\n",
        "\n",
        "model = tf.keras.Model([inp1, inp2], out)\n",
        "model.summary()\n",
        "\n",
        "loss = tf.keras.losses.CategoricalCrossentropy()\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-4)\n",
        "metrics = ['accuracy']\n",
        "saved_weight = os.path.join('/content/drive/MyDrive','saved_models_chall3', 'model_{epoch:02d}.hdf5')\n",
        "model_chk = tf.keras.callbacks.ModelCheckpoint(saved_weight,\n",
        "                                              monitor='val_loss',\n",
        "                                              verbose=1,\n",
        "                                              save_best_only=True,\n",
        "                                              save_weights_only=False\n",
        "                                              )\n",
        "es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=1, restore_best_weights=True)\n",
        "\n",
        "\n",
        "model.compile(metrics=metrics, optimizer=optimizer, loss=loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YJ2CcdwliOU",
        "outputId": "c0e83a62-92c1-408f-838f-7438365ec469"
      },
      "source": [
        "model = tf.keras.models.load_model(os.path.join('/content/drive/MyDrive','saved_models_chall3', 'model_10.hdf5'))\n",
        "model.fit(gen_train, steps_per_epoch=len(gen_train), \n",
        "                    validation_data=gen_val, validation_steps=len(gen_val),\n",
        "                    epochs = 100, callbacks = [model_chk, es_callback])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "137/137 [==============================] - 11s 65ms/step - loss: 0.7932 - accuracy: 0.6691 - val_loss: 1.0320 - val_accuracy: 0.5978\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.03202, saving model to /content/drive/MyDrive/saved_models_chall3/model_01.hdf5\n",
            "Epoch 2/100\n",
            "137/137 [==============================] - 7s 53ms/step - loss: 0.7694 - accuracy: 0.6799 - val_loss: 1.0793 - val_accuracy: 0.5950\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 1.03202\n",
            "Epoch 3/100\n",
            "137/137 [==============================] - 7s 54ms/step - loss: 0.7532 - accuracy: 0.6854 - val_loss: 1.0926 - val_accuracy: 0.5945\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 1.03202\n",
            "Epoch 4/100\n",
            "137/137 [==============================] - 7s 54ms/step - loss: 0.7378 - accuracy: 0.6918 - val_loss: 1.0908 - val_accuracy: 0.5975\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 1.03202\n",
            "Epoch 5/100\n",
            "137/137 [==============================] - 7s 53ms/step - loss: 0.7231 - accuracy: 0.6968 - val_loss: 1.0963 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 1.03202\n",
            "Epoch 6/100\n",
            "137/137 [==============================] - 7s 53ms/step - loss: 0.7155 - accuracy: 0.7005 - val_loss: 1.1084 - val_accuracy: 0.6010\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 1.03202\n",
            "Epoch 7/100\n",
            "137/137 [==============================] - 7s 52ms/step - loss: 0.6967 - accuracy: 0.7078 - val_loss: 1.1782 - val_accuracy: 0.6010\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 1.03202\n",
            "Epoch 8/100\n",
            "137/137 [==============================] - 7s 52ms/step - loss: 0.6892 - accuracy: 0.7112 - val_loss: 1.1419 - val_accuracy: 0.6021\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 1.03202\n",
            "Epoch 9/100\n",
            "137/137 [==============================] - 7s 51ms/step - loss: 0.6747 - accuracy: 0.7148 - val_loss: 1.1837 - val_accuracy: 0.6006\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 1.03202\n",
            "Epoch 10/100\n",
            "137/137 [==============================] - 7s 51ms/step - loss: 0.6646 - accuracy: 0.7201 - val_loss: 1.1782 - val_accuracy: 0.6025\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 1.03202\n",
            "Epoch 11/100\n",
            "137/137 [==============================] - 7s 52ms/step - loss: 0.6469 - accuracy: 0.7285 - val_loss: 1.2212 - val_accuracy: 0.6044\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 1.03202\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00011: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe87f9b71d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQ_Ucwekocqr",
        "outputId": "f5968ad8-f929-4974-abdd-61a1ddcbdf34"
      },
      "source": [
        "def create_csv(results, results_dir='./'):\n",
        "    csv_fname = 'results_'\n",
        "    csv_fname += datetime.now().strftime('%b%d_%H-%M-%S') + '.csv'\n",
        "    with open(os.path.join(results_dir, csv_fname), 'w') as f:\n",
        "        f.write('Id,Category\\n')\n",
        "        for key, value in results.items():\n",
        "            f.write(str(key) + ',' + str(value) + '\\n')\n",
        "\n",
        "testJsonName = 'test.json'\n",
        "testJsonPath = os.path.join(datasetName, testJsonName)\n",
        "\n",
        "testTensors = os.path.join(datasetName, \"test_tensors_encoder.json\")\n",
        "\n",
        "with open(testJsonPath,'r') as json_file_test:\n",
        "    data_test = json.load(json_file_test)\n",
        "    json_file_test.close()\n",
        "\n",
        "with open(testTensors,'r') as json_file_test:\n",
        "    test_features = json.load(json_file_test)\n",
        "    json_file_test.close()\n",
        "\n",
        "print('Test set length:' + str(len(data_test)))\n",
        "test_gen = CustomDataGenerator(data_test, 1, tok, test_features, maxSentenceLen=maxLength,\n",
        "                               shuffle=False, test=True)\n",
        "\n",
        "predictions = model.predict(test_gen)\n",
        "print('Predictions vector length:' + str(len(predictions)))\n",
        "\n",
        "results = {}\n",
        "\n",
        "work_pr = []\n",
        "for i in range(len(predictions)):\n",
        "    work_pr.append(tf.argmax(predictions[i], axis=-1).numpy())\n",
        "\n",
        "for i in range(len(data_test)):\n",
        "    results[data_test[i]['question_id']] = work_pr[i]\n",
        "\n",
        "create_csv(results)\n",
        "print('CSV written!')\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test set length:6372\n",
            "Predictions vector length:6372\n",
            "CSV written!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}