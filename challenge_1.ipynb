{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "challenge_1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPjy53iatoRpUoH5nSynSDJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicologhielmetti/AN2DL-challenges/blob/master/challenge_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rj2Nr4tkqYwL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bGLZVzosVOx"
      },
      "source": [
        "# Data Preprocessing\n",
        "The dataset provided for this challenge is composed by xx images of different height and width. In order to obtain a standard shape for all images, a particular function has been used, namely `tf.keras.preprocessing.image.smart_resize()`.\n",
        "\n",
        "This function resizes images to a specified target size without affecting the aspect ratio. This step is due to the successive batching of all images that requires a common format for all of them.\n",
        "In order to avoid a loss of information that would have been caused by applying a crop, it has been computed what the max width/height of the images was by implementing `getMaxImageSize(dataset_dir)`.\n",
        "\n",
        "This function returns the maximum (width,height), considering all the images of the provided dataset.\n",
        "For what regards data augmentation and the splitting of the data into two distinct sets, namely train and validation, it has been used the following script which assigns a fraction of 30% of the imgaes to the validation set; the rest will be assigned to the training set.\n",
        "\n",
        "```\n",
        "train_data_gen = ImageDataGenerator ( rotation_range=10,            \n",
        "                                      width_shift_range=10,\n",
        "                                      height_shift_range=10,\n",
        "                                      zoom_range=0.3, \n",
        "                                      horizontal_flip=True,\n",
        "                                      fill_mode='reflect',\n",
        "                                      rescale=1. / 255,\n",
        "                                      validation_split=0.3,  \n",
        "                                      preproc_funct=smart_resize()  \n",
        "                                    )\n",
        "```\n",
        "Considering that a strict division of the images in subdirectories representing the target classes is required for the functions involved in the creation of augmented images, we implemented a specific function that requires a ```json_definition``` for the subdirectory construction and the path where such images are located:\n",
        "\n",
        "\n",
        "# Model Design\n",
        "\n",
        "\n",
        "\n",
        "> Custom Models\n",
        "\n",
        "\n",
        "1.  Custom Model 1\n",
        "2.  Custom Model 2\n",
        "3.  Custom Model 3\n",
        "\n",
        "A custom model with six convolutional layers to perform feature extraction and five layers used to perform classification has been implemented. Here early stopping, dropout and l2-regularization are used to prevent overfitting. A low drop-out probability has been selected given the presence of different same-aimed techniques in the architecture.\n",
        "\n",
        "```\n",
        "self.classifier.add(tf.keras.layers.Dense(units=512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "self.classifier.add(tf.keras.layers.Dropout(0.2))\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "> Transfer Learning & Fine Tuning\n",
        "\n",
        "After the realization of custom models, it has been decided to implement the transfer learning procedure, along with fine tuning, in order to exploit and explore the capabilities of features extractors of some popular networks and thus improve the performances on the classification task proposed by this challenge. The selected architecures are VGG16, VGG19 in two different implementations and XCeption. \n",
        "\n",
        "\n",
        "1.   VGG_16\n",
        "\n",
        "\n",
        "```\n",
        "tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=(img_h, img_w, 3))\n",
        "```\n",
        "For what concernes VGG16 a single Dense layer with an higher, with respect to VGG19 and XCeption, number of nodes has been selected as top of the network respecting the original architecture. \n",
        "```\n",
        "model.add(tf.keras.layers.Dense(units=512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
        "model.add(tf.keras.layers.Dense(units=num_classes, activation='softmax'))\n",
        "```\n",
        "A short fine tuning procedure has been implemented to keep the ability of the feature extractor of the network non-specific and basically unaltered.\n",
        "\n",
        "```\n",
        "finetuning = True\n",
        "\n",
        "if finetuning:\n",
        "    freeze_until = 15\n",
        "    \n",
        "    for layer in vgg.layers[:freeze_until]:\n",
        "        layer.trainable = False\n",
        "else:\n",
        "    vgg.trainable = False\n",
        "```\n",
        "\n",
        "\n",
        "2.   VGG_19\n",
        "\n",
        "```\n",
        "tf.keras.applications.VGG19(weights='imagenet', include_top=False, input_shape=(img_h, img_w, 3))\n",
        "```\n",
        "\n",
        "In VGG19 a three layered architecture with decreasing number of nodes has been selected as the goal was to learn a good combination of the features extracted by the architecure itself.\n",
        "\n",
        "\n",
        "```\n",
        "model.add(tf.keras.layers.Dense(units=256, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(units=64, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(units=num_classes, activation='softmax'))\n",
        "```\n",
        "A slower learning rate, with respect to others architectures,was required by this network to reach good performances on the validation set.\n",
        "\n",
        "Given the length of the network, in order to adapt it to the specific task a long fine tuning procedure has been chosen.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "freeze_until = 5\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "3.   Xception\n",
        "\n",
        "```\n",
        "vgg = tf.keras.applications.Xception(weights='imagenet', include_top=False, input_shape=(img_h, img_w, 3))\n",
        "```\n",
        "\n",
        "The same motivations for the choice of the three layered architecture and fine tuning depth still apply to the Xception network as well as for the VGG19 one.\n",
        "\n",
        "# Model Selection\n",
        "Yet to come\n",
        "#Results\n",
        "Yet to come\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}