{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicologhielmetti/AN2DL-challenges/blob/master/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-jkRdXZjSbx",
        "colab": {
          "background_save": true
        }
      },
      "source": [
        "!pip install gdown\n",
        "!gdown https://drive.google.com/uc?id=1Mv7vKoI-QL6kV-1TIDE7N67_L0LXvJAg\n",
        "!unzip /content/ANDL2.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-MbZP061uud",
        "outputId": "3e6075b0-29e6-4a9c-c921-9918a26faa61",
        "colab": {
          "background_save": true
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70TyR7ZHDScm",
        "colab": {
          "background_save": true
        }
      },
      "source": [
        "import json\n",
        "import os\n",
        "import shutil\n",
        "from datetime import datetime\n",
        "from functools import partial\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorboard import program\n",
        "\n",
        "from keras.regularizers import l1\n",
        "SEED = 1996\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6FiWcenqn79",
        "colab": {
          "background_save": true
        }
      },
      "source": [
        "class ConvBlock(tf.keras.Model):\n",
        "    def __init__(self, num_filters):\n",
        "        super(ConvBlock, self).__init__()\n",
        "        self.conv2d = tf.keras.layers.Conv2D(filters=num_filters,\n",
        "                                             kernel_size=(3, 3),\n",
        "                                             strides=(1, 1),\n",
        "                                             padding='same',\n",
        "                                             kernel_regularizer=l1(5e-4),\n",
        "                                             bias_regularizer=l1(5e-4))\n",
        "        self.batch_norm = tf.keras.layers.BatchNormalization()\n",
        "        self.activation = tf.keras.layers.ReLU()  # we can specify the activation function directly in Conv2D\n",
        "        self.pooling = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
        "\n",
        "    def call(self, inputs, **kwargs):\n",
        "        x = self.conv2d(inputs)\n",
        "        x = self.batch_norm(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.pooling(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class CNNClassifier(tf.keras.Model):\n",
        "    def __init__(self, depth, start_f, num_classes):\n",
        "        super(CNNClassifier, self).__init__()\n",
        "\n",
        "        self.feature_extractor = tf.keras.Sequential()\n",
        "\n",
        "        for i in range(depth):\n",
        "            self.feature_extractor.add(ConvBlock(num_filters=start_f))\n",
        "            start_f *= 2\n",
        "\n",
        "        self.flatten = tf.keras.layers.Flatten()\n",
        "        self.classifier = tf.keras.Sequential()\n",
        "        self.classifier.add(tf.keras.layers.Dense(units=512, activation='relu', kernel_regularizer=l1(5e-4), bias_regularizer=l1(5e-4)))\n",
        "        self.classifier.add(tf.keras.layers.Dropout(0.2))\n",
        "        self.classifier.add(tf.keras.layers.Dense(units=256, activation='relu', kernel_regularizer=l1(5e-4), bias_regularizer=l1(5e-4)))\n",
        "        self.classifier.add(tf.keras.layers.Dropout(0.2))\n",
        "        self.classifier.add(tf.keras.layers.Dense(units=128, activation='relu', kernel_regularizer=l1(5e-4), bias_regularizer=l1(5e-4)))\n",
        "        self.classifier.add(tf.keras.layers.Dropout(0.2))\n",
        "        self.classifier.add(tf.keras.layers.Dense(units=64, activation='relu', kernel_regularizer=l1(5e-4), bias_regularizer=l1(5e-4)))\n",
        "        self.classifier.add(tf.keras.layers.Dropout(0.2))\n",
        "        self.classifier.add(tf.keras.layers.Dense(units=num_classes, activation='softmax'))\n",
        "\n",
        "    def call(self, inputs, **kwargs):\n",
        "        x = self.feature_extractor(inputs)\n",
        "        x = self.flatten(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "    def summary(self, line_length=None, positions=None, print_fn=None):\n",
        "        super(CNNClassifier, self).summary(line_length, positions, print_fn)\n",
        "        self.feature_extractor.summary()\n",
        "        self.classifier.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FulVNpNKqPoG",
        "colab": {
          "background_save": true
        }
      },
      "source": [
        "def divideDatasetInTargetFolders(json_definition, dataset_path):\n",
        "    for elem in json_definition:\n",
        "        dest_dir = os.path.join(dataset_path, str(json_definition[elem]))\n",
        "        if not os.path.isdir(dest_dir):\n",
        "            os.mkdir(dest_dir)\n",
        "        try:\n",
        "            shutil.move(os.path.join(dataset_path, elem),\n",
        "                        os.path.join(dest_dir, elem)\n",
        "                        )\n",
        "        except FileNotFoundError as e:\n",
        "            print(\"File not found: \" + str(e))\n",
        "            continue\n",
        "    os.mkdir(os.path.join(dataset_path, \"augmented\"))\n",
        "    os.mkdir(os.path.join(dataset_path, \"augmented/training\"))\n",
        "    os.mkdir(os.path.join(dataset_path, \"augmented/validation\"))\n",
        "\n",
        "\n",
        "def getMaxImageSize(dataset_dir):\n",
        "    max_w = 0\n",
        "    max_h = 0\n",
        "    path = os.path.join(os.getcwd(), dataset_dir)\n",
        "    for filename in os.listdir(path):\n",
        "        if filename.endswith(\".jpg\"):\n",
        "            image = Image.open(os.path.join(path, filename))\n",
        "            width, height = image.size\n",
        "            max_w = width if width > max_w else max_w\n",
        "            max_h = height if height > max_h else max_h\n",
        "        else:\n",
        "            print(\"This file -> \" + filename + \" is not .jpg\")\n",
        "    return max_w, max_h\n",
        "\n",
        "\n",
        "def getMinImageSize(dataset_dir, max_w, max_h):\n",
        "    min_w = max_w\n",
        "    min_h = max_h\n",
        "    for filename in os.listdir(dataset_dir):\n",
        "        if filename.endswith(\".jpg\"):\n",
        "            image = Image.open(os.path.join(dataset_dir, filename))\n",
        "            width, height = image.size\n",
        "            min_w = width if width < min_w else min_w\n",
        "            min_h = height if height < min_h else min_h\n",
        "        else:\n",
        "            print(\"This file -> \" + filename + \" is not .jpg\")\n",
        "    return min_w, min_h"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgeZo91gqUEe",
        "colab": {
          "background_save": true
        }
      },
      "source": [
        "train_path = os.path.join(os.getcwd(), 'MaskDataset/training')\n",
        "test_path  = os.path.join(os.getcwd(), 'MaskDataset/test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9sBYyixqZIL",
        "colab": {
          "background_save": true
        }
      },
      "source": [
        "division_dict = json.load(\n",
        "  open(os.path.join(os.getcwd(), 'MaskDataset/train_gt.json'))\n",
        ")\n",
        "\n",
        "divideDatasetInTargetFolders(division_dict, train_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VK0d9f1gqhla",
        "outputId": "467ed90f-533d-4cb9-d863-f564d1786588",
        "colab": {
          "background_save": true
        }
      },
      "source": [
        "# remember to check both train and test datasets to be sure of max dimensions\n",
        "max_w, max_h = max(getMaxImageSize(os.path.join(train_path, '0')),\n",
        "                   getMaxImageSize(os.path.join(train_path, '1')),\n",
        "                   getMaxImageSize(os.path.join(train_path, '2')))\n",
        "print(\"Maximum width and height: \" + str((max_w, max_h)))\n",
        "\n",
        "min_w, min_h = min(getMinImageSize(os.path.join(train_path, '0'), max_w, max_h),\n",
        "                   getMinImageSize(os.path.join(train_path, '1'), max_w, max_h),\n",
        "                   getMinImageSize(os.path.join(train_path, '2'), max_w, max_h))\n",
        "print(\"Minimum width and height:  \" + str((min_w, min_h)))\n",
        "print(\"Maximum width  expansion:  \" + str(max_w - min_w) + \", increase ratio: \" +\n",
        "      str(float(max_w) / float(max_w - min_w)))\n",
        "print(\"Maximum height expansion:  \" + str(max_h - min_h) + \", increase ratio: \" +\n",
        "      str(float(max_h) / float(max_h - min_h)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maximum width and height: (612, 612)\n",
            "Minimum width and height:  (345, 325)\n",
            "Maximum width  expansion:  267, increase ratio: 2.292134831460674\n",
            "Maximum height expansion:  287, increase ratio: 2.132404181184669\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F38AucnZqid9",
        "outputId": "d955efcb-653a-46ef-fe60-b1aca55c692d",
        "colab": {
          "background_save": true
        }
      },
      "source": [
        "preproc_fun_fixed = partial(tf.keras.preprocessing.image.smart_resize, size=(max_w, max_h))\n",
        "\n",
        "train_data_gen = ImageDataGenerator(rotation_range=10,\n",
        "                                    width_shift_range=10,\n",
        "                                    height_shift_range=10,\n",
        "                                    zoom_range=0.3,\n",
        "                                    horizontal_flip=True,\n",
        "                                    fill_mode='reflect',\n",
        "                                    rescale=1. / 255,\n",
        "                                    validation_split=0.3,\n",
        "                                    preprocessing_function=preproc_fun_fixed\n",
        "                                    )\n",
        "\n",
        "test_data_gen = ImageDataGenerator(rescale=1. / 255, preprocessing_function=preproc_fun_fixed)\n",
        "\n",
        "classes = ['0', '1', '2']\n",
        "save_dir = os.path.join(train_path, 'augmented')\n",
        "\n",
        "bs = 32\n",
        "\n",
        "train_gen = train_data_gen.flow_from_directory(train_path,\n",
        "                                               target_size=(max_w, max_h),\n",
        "                                               seed=SEED,\n",
        "                                               classes=classes,\n",
        "                                               #save_prefix='training_aug',\n",
        "                                               #save_to_dir=os.path.join(save_dir, 'training'),\n",
        "                                               subset='training',\n",
        "                                               shuffle=True,\n",
        "                                               batch_size=bs\n",
        "                                               )\n",
        "\n",
        "valid_gen = train_data_gen.flow_from_directory(train_path,\n",
        "                                               target_size=(max_w, max_h),\n",
        "                                               seed=SEED,\n",
        "                                               classes=classes,\n",
        "                                               #save_prefix='validation',\n",
        "                                               #save_to_dir=os.path.join(save_dir, 'validation'),\n",
        "                                               subset='validation',\n",
        "                                               shuffle=False,\n",
        "                                               batch_size=bs\n",
        "                                               )\n",
        "\n",
        "import pandas as pd\n",
        "images = [f for f in os.listdir(test_path)]\n",
        "images = pd.DataFrame(images)\n",
        "images.rename(columns = {0:'filename'}, inplace = True)\n",
        "images[\"class\"] = 'test'\n",
        "\n",
        "test_gen = test_data_gen.flow_from_dataframe(images,\n",
        "                                               test_path,\n",
        "                                               batch_size=bs,\n",
        "                                               target_size=(max_h, max_w),\n",
        "                                               class_mode='categorical',\n",
        "                                               shuffle=False,\n",
        "                                               seed=SEED)\n",
        "\n",
        "\n",
        "test_gen.reset()\n",
        "\n",
        "train_set = tf.data.Dataset.from_generator(lambda: train_gen,\n",
        "                                           output_types=(tf.float32, tf.float32),\n",
        "                                           output_shapes=(\n",
        "                                               [None, max_w, max_h, 3],\n",
        "                                               [None, len(classes)]\n",
        "                                           ))\n",
        "\n",
        "validation_set = tf.data.Dataset.from_generator(lambda: valid_gen,\n",
        "                                                output_types=(tf.float32, tf.float32),\n",
        "                                                output_shapes=(\n",
        "                                                    [None, max_w, max_h, 3],\n",
        "                                                    [None, len(classes)]\n",
        "                                                ))\n",
        "\n",
        "test_set = tf.data.Dataset.from_generator(lambda: test_gen,\n",
        "                                          output_types=(tf.float32, tf.float32),\n",
        "                                          output_shapes=(\n",
        "                                              [None, max_w, max_h, 3],\n",
        "                                              [None, len(classes)]\n",
        "                                          ))\n",
        "\n",
        "train_set.repeat()\n",
        "validation_set.repeat()\n",
        "test_set.repeat()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 3930 images belonging to 3 classes.\n",
            "Found 1684 images belonging to 3 classes.\n",
            "Found 450 validated image filenames belonging to 1 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<RepeatDataset shapes: ((None, 612, 612, 3), (None, 3)), types: (tf.float32, tf.float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOqm4Q4Oqyr7",
        "outputId": "09fe013b-3344-4f6b-f858-54b5dfcf7392",
        "colab": {
          "background_save": true
        }
      },
      "source": [
        "start_f = 6\n",
        "depth = 6\n",
        "\n",
        "model = CNNClassifier(depth=depth,\n",
        "                      start_f=start_f,\n",
        "                      num_classes=len(classes)\n",
        "                      )\n",
        "\n",
        "model.build(input_shape=(None, max_h, max_w, 3))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"cnn_classifier\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "sequential (Sequential)      (None, 9, 9, 192)         223020    \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            multiple                  0         \n",
            "_________________________________________________________________\n",
            "sequential_1 (Sequential)    (None, 3)                 8135811   \n",
            "=================================================================\n",
            "Total params: 8,358,831\n",
            "Trainable params: 8,358,075\n",
            "Non-trainable params: 756\n",
            "_________________________________________________________________\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv_block (ConvBlock)       (None, 306, 306, 6)       192       \n",
            "_________________________________________________________________\n",
            "conv_block_1 (ConvBlock)     (None, 153, 153, 12)      708       \n",
            "_________________________________________________________________\n",
            "conv_block_2 (ConvBlock)     (None, 76, 76, 24)        2712      \n",
            "_________________________________________________________________\n",
            "conv_block_3 (ConvBlock)     (None, 38, 38, 48)        10608     \n",
            "_________________________________________________________________\n",
            "conv_block_4 (ConvBlock)     (None, 19, 19, 96)        41952     \n",
            "_________________________________________________________________\n",
            "conv_block_5 (ConvBlock)     (None, 9, 9, 192)         166848    \n",
            "=================================================================\n",
            "Total params: 223,020\n",
            "Trainable params: 222,264\n",
            "Non-trainable params: 756\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 512)               7963136   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 3)                 195       \n",
            "=================================================================\n",
            "Total params: 8,135,811\n",
            "Trainable params: 8,135,811\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGfrCpzbrfwL",
        "colab": {
          "background_save": true
        }
      },
      "source": [
        "callbacks = []\n",
        "tensorboard = False\n",
        "if tensorboard:\n",
        "  tracking_address = os.path.join(os.getcwd(), \"tracking_dir\")\n",
        "  tb = program.TensorBoard()\n",
        "  tb.configure(argv=[None, '--logdir', tracking_address])\n",
        "  url = tb.launch()\n",
        "\n",
        "  if not os.path.exists(tracking_address):\n",
        "      os.makedirs(tracking_address)\n",
        "\n",
        "  now = datetime.now().strftime('%b%d_%H-%M-%S')\n",
        "\n",
        "  model_name = 'CNN'\n",
        "\n",
        "  exp_dir = os.path.join(tracking_address, model_name + '_' + str(now))\n",
        "  if not os.path.exists(exp_dir):\n",
        "      os.makedirs(exp_dir)\n",
        "\n",
        "  ckpt_dir = os.path.join(exp_dir, 'ckpts')\n",
        "  if not os.path.exists(ckpt_dir):\n",
        "      os.makedirs(ckpt_dir)\n",
        "\n",
        "  ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp_{epoch:02d}.ckpt'),\n",
        "                                                    save_weights_only=True)  # False to save the model directly\n",
        "  callbacks.append(ckpt_callback)\n",
        "\n",
        "  tb_dir = os.path.join(exp_dir, 'tb_logs')\n",
        "  if not os.path.exists(tb_dir):\n",
        "      os.makedirs(tb_dir)\n",
        "\n",
        "  # By default shows losses and metrics for both training and validation\n",
        "  tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir,\n",
        "                                              profile_batch=0,\n",
        "                                              histogram_freq=1)  # if 1 shows weights histograms\n",
        "  callbacks.append(tb_callback)\n",
        "  %load_ext tensorboard\n",
        "  %tensorboard --logdir /content/tracking_dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daD1-vy-urJF",
        "colab": {
          "background_save": true
        }
      },
      "source": [
        "early_stop = True\n",
        "if early_stop:\n",
        "    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=1, restore_best_weights=True)\n",
        "    callbacks.append(es_callback)\n",
        "    cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath = os.getcwd() + '/drive/My Drive/weights_nik.h5',\n",
        "      verbose=1, save_best_only=True, save_weights_only=True)\n",
        "    callbacks.append(cp_callback)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPYQd2vQvp8R",
        "colab": {
          "background_save": true
        }
      },
      "source": [
        "loss = tf.keras.losses.CategoricalCrossentropy()\n",
        "# maybe explore learning rate solutions\n",
        "lr = 1e-3\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "metrics = ['accuracy']\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tC-b2uorkO0",
        "outputId": "809bed5a-785d-4d41-f214-109db4da535b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train = True\n",
        "retrain = True\n",
        "if train:\n",
        "  if retrain:\n",
        "    model.load_weights('/content/drive/My Drive/weights_nik.h5')\n",
        "  model.fit(x=train_set,\n",
        "            epochs=100,  #### set repeat in training dataset\n",
        "            steps_per_epoch=len(train_gen),\n",
        "            validation_data=validation_set,\n",
        "            validation_steps=len(valid_gen),\n",
        "            callbacks=callbacks)\n",
        "else:\n",
        "  model.load_weights('/content/drive/My Drive/weights_nik.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "123/123 [==============================] - ETA: 0s - loss: 0.6520 - accuracy: 0.7807\n",
            "Epoch 00001: val_loss improved from inf to 0.64474, saving model to /content/drive/My Drive/weights_nik.h5\n",
            "123/123 [==============================] - 496s 4s/step - loss: 0.6520 - accuracy: 0.7807 - val_loss: 0.6447 - val_accuracy: 0.7666\n",
            "Epoch 2/100\n",
            "123/123 [==============================] - ETA: 0s - loss: 0.6238 - accuracy: 0.7840\n",
            "Epoch 00002: val_loss improved from 0.64474 to 0.63107, saving model to /content/drive/My Drive/weights_nik.h5\n",
            "123/123 [==============================] - 505s 4s/step - loss: 0.6238 - accuracy: 0.7840 - val_loss: 0.6311 - val_accuracy: 0.7797\n",
            "Epoch 3/100\n",
            "123/123 [==============================] - ETA: 0s - loss: 0.6189 - accuracy: 0.7819\n",
            "Epoch 00003: val_loss did not improve from 0.63107\n",
            "123/123 [==============================] - 505s 4s/step - loss: 0.6189 - accuracy: 0.7819 - val_loss: 0.6599 - val_accuracy: 0.7631\n",
            "Epoch 4/100\n",
            "123/123 [==============================] - ETA: 0s - loss: 0.6202 - accuracy: 0.7774\n",
            "Epoch 00004: val_loss did not improve from 0.63107\n",
            "123/123 [==============================] - 499s 4s/step - loss: 0.6202 - accuracy: 0.7774 - val_loss: 0.6504 - val_accuracy: 0.7553\n",
            "Epoch 5/100\n",
            "123/123 [==============================] - ETA: 0s - loss: 0.6138 - accuracy: 0.7781\n",
            "Epoch 00005: val_loss did not improve from 0.63107\n",
            "123/123 [==============================] - 505s 4s/step - loss: 0.6138 - accuracy: 0.7781 - val_loss: 0.6350 - val_accuracy: 0.7660\n",
            "Epoch 6/100\n",
            "123/123 [==============================] - ETA: 0s - loss: 0.6173 - accuracy: 0.7771\n",
            "Epoch 00006: val_loss did not improve from 0.63107\n",
            "123/123 [==============================] - 505s 4s/step - loss: 0.6173 - accuracy: 0.7771 - val_loss: 0.6770 - val_accuracy: 0.7536\n",
            "Epoch 7/100\n",
            "123/123 [==============================] - ETA: 0s - loss: 0.6191 - accuracy: 0.7799\n",
            "Epoch 00007: val_loss did not improve from 0.63107\n",
            "123/123 [==============================] - 492s 4s/step - loss: 0.6191 - accuracy: 0.7799 - val_loss: 0.6315 - val_accuracy: 0.7761\n",
            "Epoch 8/100\n",
            "123/123 [==============================] - ETA: 0s - loss: 0.6188 - accuracy: 0.7791\n",
            "Epoch 00008: val_loss did not improve from 0.63107\n",
            "123/123 [==============================] - 495s 4s/step - loss: 0.6188 - accuracy: 0.7791 - val_loss: 0.6485 - val_accuracy: 0.7565\n",
            "Epoch 9/100\n",
            "123/123 [==============================] - ETA: 0s - loss: 0.6102 - accuracy: 0.7845\n",
            "Epoch 00009: val_loss improved from 0.63107 to 0.61832, saving model to /content/drive/My Drive/weights_nik.h5\n",
            "123/123 [==============================] - 487s 4s/step - loss: 0.6102 - accuracy: 0.7845 - val_loss: 0.6183 - val_accuracy: 0.7803\n",
            "Epoch 10/100\n",
            "123/123 [==============================] - ETA: 0s - loss: 0.6088 - accuracy: 0.7850\n",
            "Epoch 00010: val_loss did not improve from 0.61832\n",
            "123/123 [==============================] - 505s 4s/step - loss: 0.6088 - accuracy: 0.7850 - val_loss: 0.6472 - val_accuracy: 0.7625\n",
            "Epoch 11/100\n",
            "123/123 [==============================] - ETA: 0s - loss: 0.5976 - accuracy: 0.7926\n",
            "Epoch 00011: val_loss did not improve from 0.61832\n",
            "123/123 [==============================] - 520s 4s/step - loss: 0.5976 - accuracy: 0.7926 - val_loss: 0.6237 - val_accuracy: 0.7803\n",
            "Epoch 12/100\n",
            "123/123 [==============================] - ETA: 0s - loss: 0.6007 - accuracy: 0.7878\n",
            "Epoch 00012: val_loss improved from 0.61832 to 0.60881, saving model to /content/drive/My Drive/weights_nik.h5\n",
            "123/123 [==============================] - 512s 4s/step - loss: 0.6007 - accuracy: 0.7878 - val_loss: 0.6088 - val_accuracy: 0.7696\n",
            "Epoch 13/100\n",
            "123/123 [==============================] - ETA: 0s - loss: 0.6052 - accuracy: 0.7819\n",
            "Epoch 00013: val_loss did not improve from 0.60881\n",
            "123/123 [==============================] - 499s 4s/step - loss: 0.6052 - accuracy: 0.7819 - val_loss: 0.6228 - val_accuracy: 0.7720\n",
            "Epoch 14/100\n",
            "123/123 [==============================] - ETA: 0s - loss: 0.5916 - accuracy: 0.7919\n",
            "Epoch 00014: val_loss did not improve from 0.60881\n",
            "123/123 [==============================] - 488s 4s/step - loss: 0.5916 - accuracy: 0.7919 - val_loss: 0.6168 - val_accuracy: 0.7773\n",
            "Epoch 15/100\n",
            "123/123 [==============================] - ETA: 0s - loss: 0.5926 - accuracy: 0.7908\n",
            "Epoch 00015: val_loss did not improve from 0.60881\n",
            "123/123 [==============================] - 483s 4s/step - loss: 0.5926 - accuracy: 0.7908 - val_loss: 0.7182 - val_accuracy: 0.7435\n",
            "Epoch 16/100\n",
            "123/123 [==============================] - ETA: 0s - loss: 0.5947 - accuracy: 0.7898\n",
            "Epoch 00016: val_loss improved from 0.60881 to 0.60075, saving model to /content/drive/My Drive/weights_nik.h5\n",
            "123/123 [==============================] - 500s 4s/step - loss: 0.5947 - accuracy: 0.7898 - val_loss: 0.6007 - val_accuracy: 0.7779\n",
            "Epoch 17/100\n",
            "123/123 [==============================] - ETA: 0s - loss: 0.5839 - accuracy: 0.7972\n",
            "Epoch 00017: val_loss did not improve from 0.60075\n",
            "123/123 [==============================] - 514s 4s/step - loss: 0.5839 - accuracy: 0.7972 - val_loss: 0.6711 - val_accuracy: 0.7506\n",
            "Epoch 18/100\n",
            "123/123 [==============================] - ETA: 0s - loss: 0.5857 - accuracy: 0.7962\n",
            "Epoch 00018: val_loss did not improve from 0.60075\n",
            "123/123 [==============================] - 487s 4s/step - loss: 0.5857 - accuracy: 0.7962 - val_loss: 0.6416 - val_accuracy: 0.7637\n",
            "Epoch 19/100\n",
            "123/123 [==============================] - ETA: 0s - loss: 0.5878 - accuracy: 0.7975\n",
            "Epoch 00019: val_loss did not improve from 0.60075\n",
            "123/123 [==============================] - 459s 4s/step - loss: 0.5878 - accuracy: 0.7975 - val_loss: 0.6183 - val_accuracy: 0.7726\n",
            "Epoch 20/100\n",
            "123/123 [==============================] - ETA: 0s - loss: 0.5951 - accuracy: 0.7901\n",
            "Epoch 00020: val_loss did not improve from 0.60075\n",
            "123/123 [==============================] - 455s 4s/step - loss: 0.5951 - accuracy: 0.7901 - val_loss: 0.6281 - val_accuracy: 0.7619\n",
            "Epoch 21/100\n",
            "123/123 [==============================] - ETA: 0s - loss: 0.5907 - accuracy: 0.7863\n",
            "Epoch 00021: val_loss did not improve from 0.60075\n",
            "123/123 [==============================] - 452s 4s/step - loss: 0.5907 - accuracy: 0.7863 - val_loss: 0.6093 - val_accuracy: 0.7779\n",
            "Epoch 22/100\n",
            " 44/123 [=========>....................] - ETA: 3:29 - loss: 0.5807 - accuracy: 0.7955"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sxal599l3y_w"
      },
      "source": [
        "#testing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5AUdikqPz10"
      },
      "source": [
        "def create_csv(results, results_dir='/content/drive/My Drive'):\n",
        "\n",
        "    csv_fname = 'results_'\n",
        "    csv_fname += datetime.now().strftime('%b%d_%H-%M-%S') + '.csv'\n",
        "\n",
        "    with open(os.path.join(results_dir, csv_fname), 'w') as f:\n",
        "\n",
        "        f.write('Id,Category\\n')\n",
        "\n",
        "        for key, value in results.items():\n",
        "            f.write(key + ',' + str(value) + '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaxCtSCLP7ss"
      },
      "source": [
        "predictions = model.predict_generator(test_gen, len(test_gen), verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocOXozSxQALv"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "results = {}\n",
        "images = test_gen.filenames\n",
        "i = 0\n",
        "\n",
        "for p in predictions:\n",
        "  prediction = np.argmax(p)\n",
        "  import ntpath\n",
        "  image_name = ntpath.basename(images[i])\n",
        "  results[image_name] = str(prediction)\n",
        "  i = i + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPg5kdscQCpz"
      },
      "source": [
        "create_csv(results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hh_M3BlGQDS9"
      },
      "source": [
        "!cp results_Nov15_11-49-28.csv \"/content/drive/My Drive/\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}